{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DQN.ipynb","provenance":[],"collapsed_sections":["9u_bVI_99Rfv","j4SkkGZU9Dd_","B9mN3hsv9Hl2","APhMTaPP9Kxl"],"toc_visible":true,"authorship_tag":"ABX9TyNoAQ4Rpbc2gTJZJ+hdiCPH"},"kernelspec":{"name":"python_defaultSpec_1596826856201","display_name":"Python 3.6.10 64-bit ('reinforcement-learning': conda)"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"553f3f2b4e164ccfbc5ddfd2d79bcdfa":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_c74e563a80954025bf54f09f6ddab1ef","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_800189801a7b4df081c2d1212396f440","IPY_MODEL_aa8baad31c564581a9bb59e9246401be"]}},"c74e563a80954025bf54f09f6ddab1ef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"800189801a7b4df081c2d1212396f440":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_8097a02df891400c914eb8d624256c91","_dom_classes":[],"description":" 48%","_model_name":"FloatProgressModel","bar_style":"","max":500,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":242,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0b41cf3738f94d26b2b02c8caf929843"}},"aa8baad31c564581a9bb59e9246401be":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_db086016d7fb441b91078372660ae2df","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 242/500 [2:41:18&lt;2:53:42, 40.40s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_709e6b240ab145f5a14d30a2955cfb2c"}},"8097a02df891400c914eb8d624256c91":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"0b41cf3738f94d26b2b02c8caf929843":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"db086016d7fb441b91078372660ae2df":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"709e6b240ab145f5a14d30a2955cfb2c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"KLAOgs3gOPy8","colab_type":"code","colab":{}},"source":["import os\n","import time\n","import cv2\n","import gym\n","import collections\n","\n","import numpy as np\n","import torch as T\n","import torch.optim as optim\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import matplotlib.pyplot as plt\n","\n","from tqdm.notebook import tqdm\n","\n","%matplotlib inline"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"rZDPJ0g-e6fh","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":36},"executionInfo":{"status":"ok","timestamp":1596816577313,"user_tz":-330,"elapsed":1619,"user":{"displayName":"Nimish S","photoUrl":"","userId":"16860995465865824316"}},"outputId":"25bd6f03-aade-4d43-f9aa-524ecee5265b"},"source":["# T.cuda.get_device_name()"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9u_bVI_99Rfv","colab_type":"text"},"source":["## **Wrappers**"]},{"cell_type":"code","metadata":{"id":"L5aHWPN-OEAJ","colab_type":"code","colab":{}},"source":["# PREPROCESS EACH FRAME\n","class PreprocessFrames(gym.ObservationWrapper):\n","    \"\"\"\n","    PREPROCESSES EACH FRAME (input = (rows, columns, 3)) [0-255]\n","    1. convert to grayscale (3 channels to 1)   -   (rows, columns, 1)  [0-255]\n","    2. resize to new shape                      -   (new_rows, new_columns)  [0-255]\n","    3. convert to nparray & reshape             -   array(1, new_rows, new_columns)  [0-255]\n","    4. scale values from 0-1                    -   array(1, new_rows, new_columns)  [0.0-1.0]\n","    \"\"\"\n","    def __init__(self, env, new_observation_shape):\n","        super().__init__(env)\n","        self.new_observation_shape = new_observation_shape\n","        self.observation_space = gym.spaces.Box(low=0.0, high=1.0, shape=self.new_observation_shape, dtype=np.float32)\n","    \n","    def observation(self, observation):\n","        temp_frame = cv2.cvtColor(observation, cv2.COLOR_RGB2GRAY)\n","        temp_frame = cv2.resize(temp_frame, self.new_observation_shape[1:], interpolation=cv2.INTER_AREA)\n","        new_observation = np.array(temp_frame).reshape(self.new_observation_shape)\n","        new_observation = new_observation / 255.0 \n","        return new_observation\n","\n","# TO BE CALLED ON EACH SINGLE IMAGE (AFTER PREPROCESS)\n","class CustomStep(gym.Wrapper):\n","    \"\"\"\n","    OVERRIDES step() & reset()\n","    1. repeats same action in 'n' skipped frames to compute faster.\n","    2. removes flicker in frames by taking max of 2 consecutive frames.\n","    \"\"\"\n","    def __init__(self, env, frame_skip, clip_reward, no_ops, fire_first):\n","        super().__init__(env)\n","        self.frame_skip = frame_skip\n","        self.observation_shape = env.observation_space.shape\n","        self.observation_buffer = np.zeros_like((2, self.observation_shape))\n","        # DURING TESTING ONLY\n","        self.clip_reward = clip_reward\n","        self.no_ops = no_ops\n","        self.fire_first = fire_first\n","\n","    def reset(self):\n","        observation = self.env.reset()\n","        # FOR no_ops\n","        no_ops = (np.random.randint(self.no_ops) + 1) if (self.no_ops > 0) else 0\n","        for _ in range(no_ops):\n","            _, _, done, _ = env.step(0) # 0 - NOOP\n","            if done: self.env.reset()\n","        # FOR fire_first\n","        if (self.fire_first):\n","            assert (self.env.get_action_meanings()[0] == 'FIRE')\n","            observation, _, _, _ = env.step(1) # 1 - FIRE\n","        self.observation_buffer = np.zeros_like((2, self.observation_shape))\n","        self.observation_buffer[0] = observation\n","        return observation\n","\n","    # RETURN FRAME_SKIPPED & FLICKER REMOVED FRAMES \n","    def step(self, action):\n","        total_reward = 0.0\n","        done = False\n","\n","        for frame in range(self.frame_skip):\n","            observation, reward, done, info = self.env.step(action)\n","            # CLIP REWARD (-1,1) IF true\n","            reward = reward if (not self.clip_reward) else np.clip(reward, -1,1)\n","            total_reward += reward\n","\n","            idx = frame % 2\n","            self.observation_buffer[idx] = observation\n","\n","            if done: break\n","\n","        observation_max = np.maximum(self.observation_buffer[0], self.observation_buffer[1])\n","        return observation_max, total_reward, done, info\n","\n","\n","# STACK OBSERVATIONS\n","class StackFrames(gym.ObservationWrapper):\n","    \"\"\"\n","    STACKS stack_size FRAMES TOGETHER AND RETURNS AS THE 'observation'\n","    1. on reset() returns first 'observation' STACKED 'stack_size' times\n","    2. observation() returns current 'observation' STACKED with 'stack_size-1' previous 'observation'\n","    \"\"\"\n","    def __init__(self, env, stack_size):\n","        super().__init__(env)\n","        self.observation_space = gym.spaces.Box(\n","                                    env.observation_space.low.repeat(stack_size, axis=0),\n","                                    env.observation_space.high.repeat(stack_size, axis=0)\n","                                 )\n","        self.stack = collections.deque(maxlen=stack_size)\n","\n","    def reset(self):\n","        self.stack.clear()\n","        observation = self.env.reset()\n","        for _ in range(self.stack.maxlen):\n","            self.stack.append(observation)\n","        observation = np.array(self.stack).reshape(self.observation_space.shape)\n","        return observation\n","        \n","    def observation(self, observation):\n","        self.stack.append(observation)\n","        observation = np.array(self.stack).reshape(self.observation_space.shape)\n","        return observation"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"R9YVrXJ0A0nd","colab_type":"code","colab":{}},"source":["# TIE EVERYTHING TOGETHER\n","def make_env(env_name, new_observation_shape=(1,84,84), stack_size=4, frame_skip=4, clip_reward=False, no_ops=0, fire_first=False):\n","    env = gym.make(env_name)\n","    env = PreprocessFrames(env, new_observation_shape=new_observation_shape)\n","    env = CustomStep(env, frame_skip=4, clip_reward=clip_reward, no_ops=no_ops, fire_first=fire_first)\n","    env = StackFrames(env, stack_size=stack_size)\n","    return env"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j4SkkGZU9Dd_","colab_type":"text"},"source":["## **ReplayBuffer**"]},{"cell_type":"code","metadata":{"id":"-SvHE9YKo0r-","colab_type":"code","colab":{}},"source":["class ReplayBuffer:\n","    def __init__(self, mem_size, observation_shape, n_actions):\n","        self.mem_size = mem_size\n","        self.mem_counter = 0\n","        # DATA\n","        self.states = np.zeros((mem_size, *observation_shape), dtype=np.float32)\n","        self.actions = np.zeros(mem_size, dtype=np.int64)\n","        self.rewards = np.zeros(mem_size, dtype=np.int64)\n","        self.states_ = np.zeros((mem_size, *observation_shape), dtype=np.float32)\n","        self.terminals = np.zeros(mem_size, dtype=bool)\n","\n","    # STORE TRANSITIONS IN BUFFER\n","    def store_transition(self, state, action, reward, state_, done):\n","        index = self.mem_counter % self.mem_size\n","        self.states[index] = state\n","        self.actions[index] = action\n","        self.rewards[index] = reward\n","        self.states_[index] = state_\n","        self.terminals[index] = done # 1 if 'done' else 0\n","        self.mem_counter += 1\n","\n","    # UNIFORMLY SAMPLES 'BUFFER' AND RETURNS A 'BATCH' OF batch_size\n","    def sample_batch(self, batch_size):\n","        max_index = min(self.mem_counter, self.mem_size)\n","        batch_indices = np.random.choice(max_index, batch_size, replace=False)\n","        states = self.states[batch_indices]\n","        actions = self.actions[batch_indices]\n","        rewards = self.rewards[batch_indices]\n","        states_ = self.states_[batch_indices]\n","        terminals = self.terminals[batch_indices]\n","        return (states, actions, rewards, states_, terminals)"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"B9mN3hsv9Hl2","colab_type":"text"},"source":["## **Network**"]},{"cell_type":"code","metadata":{"id":"N4-yaJCQ0Kci","colab_type":"code","colab":{}},"source":["class DeepQNetwork(nn.Module):\n","    def __init__(self, lr, observation_shape, n_actions, model_name, model_dir):\n","        super().__init__()\n","        self.model_dir = model_dir\n","        self.model_file = os.path.join(self.model_dir, model_name)\n","        # CNN\n","        self.conv1 = nn.Conv2d(observation_shape[0], 32, kernel_size=8, stride=4)\n","        self.conv2 = nn.Conv2d(32, 64, kernel_size=4, stride=2)\n","        self.conv3 = nn.Conv2d(64, 64, kernel_size=3, stride=1)\n","        # CNN -> ANN\n","        fc_input_dims = self.caculate_conv_output_dims(observation_shape)\n","        # ANN\n","        self.fc1 = nn.Linear(fc_input_dims, 512)\n","        self.out = nn.Linear(512, n_actions)\n","        # UTILS\n","        self.device = T.device('cuda:0' if T.cuda.is_available() else 'cpu')\n","        self.optimizer = optim.RMSprop(self.parameters(), lr=lr)\n","        self.loss = nn.MSELoss()\n","        self.to(self.device)\n","    \n","    def forward(self, state):\n","        t = F.relu(self.conv1(state))\n","        t = F.relu(self.conv2(t))\n","        t = F.relu(self.conv3(t))\n","        t = F.relu(self.fc1(t.reshape(t.shape[0], -1)))\n","        q_values = self.out(t)\n","        return q_values\n","\n","    def caculate_conv_output_dims(self, observation_shape):\n","        dims = T.zeros((1, *observation_shape))\n","        dims = self.conv1(dims)\n","        dims = self.conv2(dims)\n","        dims = self.conv3(dims)\n","        return int(np.prod(dims.shape))\n","\n","    def save_model(self):\n","        print(\"[INFO] Saving model\")\n","        checkpoint = {\n","            'model_state_dict': self.state_dict(),\n","            'optimizer_state_dict' : self.optimizer.state_dict()\n","        }\n","        T.save(checkpoint, self.model_file)\n","    \n","    def load_model(self, cpu=False):\n","        print(\"[INFO] Loading model\")\n","        \n","        map_location = T.device('cpu') if (cpu) else None\n","        \n","        checkpoint = T.load(self.model_file, map_location=map_location)\n","        self.load_state_dict(checkpoint['model_state_dict'])\n","        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"APhMTaPP9Kxl","colab_type":"text"},"source":["## **Agent**"]},{"cell_type":"code","metadata":{"id":"Jf105mZ2pb8I","colab_type":"code","colab":{}},"source":["class DQNAgent:\n","    def __init__(self, observation_shape, n_actions, lr, gamma, epsilon, epsilon_min, epsilon_decay,\n","                 mem_size, batch_size, Q_TARGET_replace_interval, algo_name, env_name, model_dir):\n","        self.observation_shape = observation_shape\n","        self.n_actions = n_actions\n","        self.LR = lr\n","        self.GAMMA = gamma\n","        self.EPSILON = epsilon\n","        self.epsilon_min = epsilon_min\n","        self.epsilon_decay = epsilon_decay\n","\n","        # MEM PARAMS\n","        self.mem_size = mem_size\n","        self.batch_size = batch_size\n","        self.memory = ReplayBuffer(mem_size, observation_shape, n_actions)\n","\n","        # MODEL PARAMS\n","        self.learn_counter = 0 # TO UPDATE TARGET NETWORK\n","        self.algo_name = algo_name\n","        self.env_name = env_name\n","        self.model_dir = model_dir\n","        self.Q_TARGET_replace_interval = Q_TARGET_replace_interval\n","        # Q1\n","        self.Q_STEP = DeepQNetwork(lr, observation_shape, n_actions,\n","                              model_name = algo_name+'_Q_STEP',\n","                              model_dir = model_dir)\n","        # Q2\n","        self.Q_TARGET = DeepQNetwork(lr, observation_shape, n_actions,\n","                              model_name = algo_name+'_Q_TARGET',\n","                              model_dir = model_dir)\n","\n","    # e-GREEDY POLICY\n","    def get_action(self, observation, greedy=False):\n","        if ( (np.random.uniform() >= self.EPSILON) or greedy):\n","            observation = T.tensor(observation, dtype=T.float32).to(self.Q_STEP.device)\n","            state = T.unsqueeze(observation, 0)\n","            actions = self.Q_STEP(state)\n","            action = T.argmax(actions).item()\n","        else:\n","            action = env.action_space.sample()\n","        return action\n","\n","    def learn(self):\n","        if (self.memory.mem_counter < self.batch_size): return # return if insufficient samples present\n","        # RESET TARGET NETWORK (1 / 1000)\n","        self.update_Q_TARGET()\n","\n","        # PREDICT Q1(s,a)\n","        states, actions, rewards, states_, terminals = self.sample_batch()\n","        q1 = self.Q_STEP(states)         # q - batch_size * n_actions\n","        indices = np.arange(self.batch_size)\n","        q1_preds = q1[indices, actions]\n","\n","        # GET Q2(s_,a_) WHERE a_ = max(Q2(s_, A))\n","        q2_ = self.Q_TARGET(states_)\n","        q2_next = (q2_.max(dim=1))[0]     # MAX VAL ACTION (without added reward)\n","        q2_next[terminals] = 0.0         # Q(s_) = 0 where terminal=1\n","        q2_targets = rewards + (self.GAMMA * q2_next)\n","\n","        # CALC LOSS & BACKPROP\n","        loss = self.Q_STEP.loss(q2_targets, q1_preds).to(self.Q_STEP.device)\n","        self.Q_STEP.optimizer.zero_grad()\n","        loss.backward()\n","        self.Q_STEP.optimizer.step()\n","\n","        self.learn_counter += 1\n","        self.decay_epsilon()\n","\n","    def update_Q_TARGET(self):\n","        if ((self.learn_counter % self.Q_TARGET_replace_interval) == 0):\n","            self.Q_TARGET.load_state_dict(self.Q_STEP.state_dict())\n","    \n","    def decay_epsilon(self):\n","        if (self.EPSILON > self.epsilon_min):\n","            self.EPSILON -= self.epsilon_decay\n","        else:\n","            self.EPSILON = self.epsilon_min\n","    \n","    def store_transition(self, state, action, reward, state_, done):\n","        self.memory.store_transition(state, action, reward, state_, done)\n","\n","    def sample_batch(self):\n","        states, actions, rewards, states_, terminals = self.memory.sample_batch(self.batch_size)\n","        states = T.tensor(states).to(self.Q_STEP.device)\n","        actions = T.tensor(actions).to(self.Q_STEP.device)\n","        rewards = T.tensor(rewards).to(self.Q_STEP.device)\n","        states_ = T.tensor(states_).to(self.Q_STEP.device)\n","        terminals = T.tensor(terminals).to(self.Q_STEP.device)\n","        return states, actions, rewards, states_, terminals\n","        \n","    def save_models(self):\n","        self.Q_STEP.save_model()\n","        self.Q_TARGET.save_model()\n","    \n","    def load_models(self, cpu=False):\n","        self.Q_STEP.load_model(cpu)\n","        self.Q_TARGET.load_model(cpu)"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"g7HQrV3WcH2c","colab_type":"text"},"source":["## **Training**"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["## TRAINING ##"]},{"cell_type":"code","metadata":{"id":"mj6YZi0aXsDX","colab_type":"code","colab":{}},"source":["env_name = 'PongNoFrameskip-v4'\n","env = make_env(env_name)\n","\n","N_EPISODES = 500\n","\n","agent = DQNAgent(observation_shape=env.observation_space.shape,\n","                 n_actions=env.action_space.n,\n","                 lr=1e-4,\n","                 gamma=0.99,\n","                 epsilon=1.0,\n","                 epsilon_min=0.06,\n","                 epsilon_decay=1e-5,\n","                 mem_size=25000,\n","                 batch_size=128,\n","                 Q_TARGET_replace_interval=1000,\n","                 algo_name='DQN',\n","                 env_name=env_name,\n","                 model_dir='./')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Rp2We9miezCT","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["553f3f2b4e164ccfbc5ddfd2d79bcdfa","c74e563a80954025bf54f09f6ddab1ef","800189801a7b4df081c2d1212396f440","aa8baad31c564581a9bb59e9246401be","8097a02df891400c914eb8d624256c91","0b41cf3738f94d26b2b02c8caf929843","db086016d7fb441b91078372660ae2df","709e6b240ab145f5a14d30a2955cfb2c"]},"outputId":"103b09cc-6906-410f-cd36-2fb46bcc1869"},"source":["episode_rewards, episode_lengths, episode_epsilons, mean_rewards = [],[],[],[]\n","best_reward = -np.inf\n","\n","for episode_n in tqdm(range(N_EPISODES)):\n","    total_reward, total_moves = 0,0\n","\n","    done = False\n","    observation = env.reset()\n","\n","    while not done:\n","        # e_GREEDY ACTION\n","        action = agent.get_action(observation)\n","        observation_, reward, done, _ = env.step(action)\n","\n","        total_reward += reward\n","        total_moves += 1\n","\n","        # STORE DATA & LEARN\n","        agent.store_transition(observation, action, reward, observation_, done)\n","        agent.learn()\n","\n","        observation = observation_\n","\n","    episode_rewards.append(total_reward)\n","    episode_lengths.append(total_moves)\n","    episode_epsilons.append(agent.EPSILON)\n","\n","    mean_reward = np.mean(episode_rewards[-100:])\n","    mean_rewards.append(mean_reward)\n","    if(mean_reward > best_reward):\n","        agent.save_models()\n","        best_reward = mean_reward\n","\n","    print(\"ITER: \",episode_n,\"\\tRWD: \",total_reward,\"\\tMEAN_RWD: \",round(mean_reward,2),\"\\tLEN: \",total_moves,\"\\tEPS: \",round(agent.EPSILON,4))"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"553f3f2b4e164ccfbc5ddfd2d79bcdfa","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=500.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["[INFO] Saving model\n","[INFO] Saving model\n","ITER:  0 \tRWD:  -20.0 \tM_RWD:  -20.0 \tLEN:  977 \tEPS:  0.9905\n","ITER:  1 \tRWD:  -21.0 \tM_RWD:  -20.5 \tLEN:  794 \tEPS:  0.9825\n","ITER:  2 \tRWD:  -21.0 \tM_RWD:  -20.666666666666668 \tLEN:  882 \tEPS:  0.9737\n","ITER:  3 \tRWD:  -21.0 \tM_RWD:  -20.75 \tLEN:  842 \tEPS:  0.9653\n","ITER:  4 \tRWD:  -21.0 \tM_RWD:  -20.8 \tLEN:  831 \tEPS:  0.957\n","ITER:  5 \tRWD:  -21.0 \tM_RWD:  -20.833333333333332 \tLEN:  824 \tEPS:  0.9488\n","ITER:  6 \tRWD:  -20.0 \tM_RWD:  -20.714285714285715 \tLEN:  930 \tEPS:  0.9395\n","ITER:  7 \tRWD:  -19.0 \tM_RWD:  -20.5 \tLEN:  1067 \tEPS:  0.9288\n","ITER:  8 \tRWD:  -19.0 \tM_RWD:  -20.333333333333332 \tLEN:  982 \tEPS:  0.919\n","ITER:  9 \tRWD:  -20.0 \tM_RWD:  -20.3 \tLEN:  838 \tEPS:  0.9106\n","ITER:  10 \tRWD:  -21.0 \tM_RWD:  -20.363636363636363 \tLEN:  813 \tEPS:  0.9025\n","ITER:  11 \tRWD:  -21.0 \tM_RWD:  -20.416666666666668 \tLEN:  912 \tEPS:  0.8933\n","ITER:  12 \tRWD:  -20.0 \tM_RWD:  -20.384615384615383 \tLEN:  1009 \tEPS:  0.8832\n","ITER:  13 \tRWD:  -20.0 \tM_RWD:  -20.357142857142858 \tLEN:  932 \tEPS:  0.8739\n","ITER:  14 \tRWD:  -21.0 \tM_RWD:  -20.4 \tLEN:  811 \tEPS:  0.8658\n","ITER:  15 \tRWD:  -20.0 \tM_RWD:  -20.375 \tLEN:  1038 \tEPS:  0.8554\n","ITER:  16 \tRWD:  -21.0 \tM_RWD:  -20.41176470588235 \tLEN:  824 \tEPS:  0.8472\n","ITER:  17 \tRWD:  -20.0 \tM_RWD:  -20.38888888888889 \tLEN:  975 \tEPS:  0.8374\n","ITER:  18 \tRWD:  -21.0 \tM_RWD:  -20.42105263157895 \tLEN:  853 \tEPS:  0.8289\n","ITER:  19 \tRWD:  -21.0 \tM_RWD:  -20.45 \tLEN:  912 \tEPS:  0.8198\n","ITER:  20 \tRWD:  -20.0 \tM_RWD:  -20.428571428571427 \tLEN:  898 \tEPS:  0.8108\n","ITER:  21 \tRWD:  -20.0 \tM_RWD:  -20.40909090909091 \tLEN:  966 \tEPS:  0.8012\n","ITER:  22 \tRWD:  -21.0 \tM_RWD:  -20.434782608695652 \tLEN:  884 \tEPS:  0.7923\n","ITER:  23 \tRWD:  -20.0 \tM_RWD:  -20.416666666666668 \tLEN:  1203 \tEPS:  0.7803\n","ITER:  24 \tRWD:  -20.0 \tM_RWD:  -20.4 \tLEN:  931 \tEPS:  0.771\n","ITER:  25 \tRWD:  -19.0 \tM_RWD:  -20.346153846153847 \tLEN:  1015 \tEPS:  0.7608\n","ITER:  26 \tRWD:  -21.0 \tM_RWD:  -20.37037037037037 \tLEN:  1126 \tEPS:  0.7496\n","ITER:  27 \tRWD:  -21.0 \tM_RWD:  -20.392857142857142 \tLEN:  886 \tEPS:  0.7407\n","ITER:  28 \tRWD:  -20.0 \tM_RWD:  -20.379310344827587 \tLEN:  889 \tEPS:  0.7318\n","ITER:  29 \tRWD:  -20.0 \tM_RWD:  -20.366666666666667 \tLEN:  917 \tEPS:  0.7226\n","ITER:  30 \tRWD:  -21.0 \tM_RWD:  -20.387096774193548 \tLEN:  764 \tEPS:  0.715\n","ITER:  31 \tRWD:  -21.0 \tM_RWD:  -20.40625 \tLEN:  1042 \tEPS:  0.7046\n","ITER:  32 \tRWD:  -20.0 \tM_RWD:  -20.393939393939394 \tLEN:  1028 \tEPS:  0.6943\n","ITER:  33 \tRWD:  -20.0 \tM_RWD:  -20.38235294117647 \tLEN:  949 \tEPS:  0.6848\n","ITER:  34 \tRWD:  -20.0 \tM_RWD:  -20.37142857142857 \tLEN:  977 \tEPS:  0.675\n","ITER:  35 \tRWD:  -21.0 \tM_RWD:  -20.38888888888889 \tLEN:  880 \tEPS:  0.6662\n","ITER:  36 \tRWD:  -21.0 \tM_RWD:  -20.405405405405407 \tLEN:  1067 \tEPS:  0.6556\n","ITER:  37 \tRWD:  -15.0 \tM_RWD:  -20.263157894736842 \tLEN:  1669 \tEPS:  0.6389\n","ITER:  38 \tRWD:  -20.0 \tM_RWD:  -20.256410256410255 \tLEN:  1048 \tEPS:  0.6284\n","ITER:  39 \tRWD:  -19.0 \tM_RWD:  -20.225 \tLEN:  1135 \tEPS:  0.6171\n","ITER:  40 \tRWD:  -19.0 \tM_RWD:  -20.195121951219512 \tLEN:  1243 \tEPS:  0.6046\n","ITER:  41 \tRWD:  -20.0 \tM_RWD:  -20.19047619047619 \tLEN:  1202 \tEPS:  0.5926\n","ITER:  42 \tRWD:  -21.0 \tM_RWD:  -20.209302325581394 \tLEN:  1006 \tEPS:  0.5825\n","ITER:  43 \tRWD:  -21.0 \tM_RWD:  -20.227272727272727 \tLEN:  1490 \tEPS:  0.5676\n","ITER:  44 \tRWD:  -20.0 \tM_RWD:  -20.22222222222222 \tLEN:  1043 \tEPS:  0.5572\n","ITER:  45 \tRWD:  -19.0 \tM_RWD:  -20.195652173913043 \tLEN:  1074 \tEPS:  0.5465\n","ITER:  46 \tRWD:  -18.0 \tM_RWD:  -20.148936170212767 \tLEN:  1224 \tEPS:  0.5342\n","ITER:  47 \tRWD:  -21.0 \tM_RWD:  -20.166666666666668 \tLEN:  1030 \tEPS:  0.5239\n","ITER:  48 \tRWD:  -18.0 \tM_RWD:  -20.122448979591837 \tLEN:  1335 \tEPS:  0.5106\n","ITER:  49 \tRWD:  -16.0 \tM_RWD:  -20.04 \tLEN:  1570 \tEPS:  0.4949\n","ITER:  50 \tRWD:  -19.0 \tM_RWD:  -20.019607843137255 \tLEN:  1171 \tEPS:  0.4832\n","ITER:  51 \tRWD:  -19.0 \tM_RWD:  -20.0 \tLEN:  1417 \tEPS:  0.469\n","ITER:  52 \tRWD:  -21.0 \tM_RWD:  -20.0188679245283 \tLEN:  1257 \tEPS:  0.4564\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  53 \tRWD:  -14.0 \tM_RWD:  -19.90740740740741 \tLEN:  1859 \tEPS:  0.4378\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  54 \tRWD:  -18.0 \tM_RWD:  -19.87272727272727 \tLEN:  1561 \tEPS:  0.4222\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  55 \tRWD:  -17.0 \tM_RWD:  -19.821428571428573 \tLEN:  1245 \tEPS:  0.4098\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  56 \tRWD:  -19.0 \tM_RWD:  -19.80701754385965 \tLEN:  1465 \tEPS:  0.3951\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  57 \tRWD:  -18.0 \tM_RWD:  -19.775862068965516 \tLEN:  1662 \tEPS:  0.3785\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  58 \tRWD:  -18.0 \tM_RWD:  -19.74576271186441 \tLEN:  1186 \tEPS:  0.3667\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  59 \tRWD:  -18.0 \tM_RWD:  -19.716666666666665 \tLEN:  1503 \tEPS:  0.3516\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  60 \tRWD:  -19.0 \tM_RWD:  -19.704918032786885 \tLEN:  1415 \tEPS:  0.3375\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  61 \tRWD:  -19.0 \tM_RWD:  -19.693548387096776 \tLEN:  1463 \tEPS:  0.3228\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  62 \tRWD:  -18.0 \tM_RWD:  -19.666666666666668 \tLEN:  1572 \tEPS:  0.3071\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  63 \tRWD:  -14.0 \tM_RWD:  -19.578125 \tLEN:  1829 \tEPS:  0.2888\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  64 \tRWD:  -14.0 \tM_RWD:  -19.49230769230769 \tLEN:  2277 \tEPS:  0.2661\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  65 \tRWD:  -16.0 \tM_RWD:  -19.439393939393938 \tLEN:  1713 \tEPS:  0.2489\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  66 \tRWD:  -16.0 \tM_RWD:  -19.388059701492537 \tLEN:  1934 \tEPS:  0.2296\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  67 \tRWD:  -15.0 \tM_RWD:  -19.323529411764707 \tLEN:  2242 \tEPS:  0.2072\n","ITER:  68 \tRWD:  -20.0 \tM_RWD:  -19.333333333333332 \tLEN:  1584 \tEPS:  0.1913\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  69 \tRWD:  -15.0 \tM_RWD:  -19.271428571428572 \tLEN:  2251 \tEPS:  0.1688\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  70 \tRWD:  -19.0 \tM_RWD:  -19.267605633802816 \tLEN:  1453 \tEPS:  0.1543\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  71 \tRWD:  -14.0 \tM_RWD:  -19.194444444444443 \tLEN:  2100 \tEPS:  0.1333\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  72 \tRWD:  -18.0 \tM_RWD:  -19.17808219178082 \tLEN:  1589 \tEPS:  0.1174\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  73 \tRWD:  -14.0 \tM_RWD:  -19.10810810810811 \tLEN:  2341 \tEPS:  0.094\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  74 \tRWD:  -19.0 \tM_RWD:  -19.106666666666666 \tLEN:  1704 \tEPS:  0.077\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  75 \tRWD:  -16.0 \tM_RWD:  -19.06578947368421 \tLEN:  2175 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  76 \tRWD:  -11.0 \tM_RWD:  -18.961038961038962 \tLEN:  2572 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  77 \tRWD:  -13.0 \tM_RWD:  -18.884615384615383 \tLEN:  2019 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  78 \tRWD:  -18.0 \tM_RWD:  -18.873417721518987 \tLEN:  1732 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  79 \tRWD:  -14.0 \tM_RWD:  -18.8125 \tLEN:  2014 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  80 \tRWD:  -12.0 \tM_RWD:  -18.728395061728396 \tLEN:  2055 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  81 \tRWD:  -13.0 \tM_RWD:  -18.658536585365855 \tLEN:  2150 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  82 \tRWD:  -6.0 \tM_RWD:  -18.50602409638554 \tLEN:  2863 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  83 \tRWD:  -7.0 \tM_RWD:  -18.36904761904762 \tLEN:  2917 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  84 \tRWD:  -5.0 \tM_RWD:  -18.211764705882352 \tLEN:  3125 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  85 \tRWD:  -7.0 \tM_RWD:  -18.08139534883721 \tLEN:  2894 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  86 \tRWD:  -10.0 \tM_RWD:  -17.988505747126435 \tLEN:  2707 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  87 \tRWD:  -10.0 \tM_RWD:  -17.897727272727273 \tLEN:  2713 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  88 \tRWD:  -7.0 \tM_RWD:  -17.775280898876403 \tLEN:  2809 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  89 \tRWD:  -4.0 \tM_RWD:  -17.622222222222224 \tLEN:  3262 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  90 \tRWD:  -6.0 \tM_RWD:  -17.494505494505493 \tLEN:  2870 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  91 \tRWD:  -7.0 \tM_RWD:  -17.380434782608695 \tLEN:  3123 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  92 \tRWD:  -5.0 \tM_RWD:  -17.247311827956988 \tLEN:  3159 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  93 \tRWD:  -3.0 \tM_RWD:  -17.095744680851062 \tLEN:  3495 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  94 \tRWD:  -2.0 \tM_RWD:  -16.936842105263157 \tLEN:  4714 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  95 \tRWD:  -10.0 \tM_RWD:  -16.864583333333332 \tLEN:  2651 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  96 \tRWD:  -5.0 \tM_RWD:  -16.742268041237114 \tLEN:  3516 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  97 \tRWD:  -1.0 \tM_RWD:  -16.581632653061224 \tLEN:  3785 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  98 \tRWD:  -9.0 \tM_RWD:  -16.505050505050505 \tLEN:  2515 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  99 \tRWD:  -2.0 \tM_RWD:  -16.36 \tLEN:  3781 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  100 \tRWD:  -5.0 \tM_RWD:  -16.21 \tLEN:  3356 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  101 \tRWD:  -6.0 \tM_RWD:  -16.06 \tLEN:  3478 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  102 \tRWD:  -4.0 \tM_RWD:  -15.89 \tLEN:  3473 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  103 \tRWD:  -2.0 \tM_RWD:  -15.7 \tLEN:  3378 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  104 \tRWD:  4.0 \tM_RWD:  -15.45 \tLEN:  3560 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  105 \tRWD:  -1.0 \tM_RWD:  -15.25 \tLEN:  3467 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  106 \tRWD:  -9.0 \tM_RWD:  -15.14 \tLEN:  2614 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  107 \tRWD:  -9.0 \tM_RWD:  -15.04 \tLEN:  2651 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  108 \tRWD:  -9.0 \tM_RWD:  -14.94 \tLEN:  2144 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  109 \tRWD:  -4.0 \tM_RWD:  -14.78 \tLEN:  2713 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  110 \tRWD:  -5.0 \tM_RWD:  -14.62 \tLEN:  2914 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  111 \tRWD:  -4.0 \tM_RWD:  -14.45 \tLEN:  2786 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  112 \tRWD:  -3.0 \tM_RWD:  -14.28 \tLEN:  3158 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  113 \tRWD:  -3.0 \tM_RWD:  -14.11 \tLEN:  2980 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  114 \tRWD:  6.0 \tM_RWD:  -13.84 \tLEN:  2508 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  115 \tRWD:  6.0 \tM_RWD:  -13.58 \tLEN:  2929 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  116 \tRWD:  2.0 \tM_RWD:  -13.35 \tLEN:  3272 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  117 \tRWD:  2.0 \tM_RWD:  -13.13 \tLEN:  3544 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  118 \tRWD:  -9.0 \tM_RWD:  -13.01 \tLEN:  2766 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  119 \tRWD:  -1.0 \tM_RWD:  -12.81 \tLEN:  3282 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  120 \tRWD:  -2.0 \tM_RWD:  -12.63 \tLEN:  3147 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  121 \tRWD:  -3.0 \tM_RWD:  -12.46 \tLEN:  3190 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  122 \tRWD:  -4.0 \tM_RWD:  -12.29 \tLEN:  2610 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  123 \tRWD:  -1.0 \tM_RWD:  -12.1 \tLEN:  3598 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  124 \tRWD:  -8.0 \tM_RWD:  -11.98 \tLEN:  2661 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  125 \tRWD:  3.0 \tM_RWD:  -11.76 \tLEN:  3003 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  126 \tRWD:  2.0 \tM_RWD:  -11.53 \tLEN:  3124 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  127 \tRWD:  4.0 \tM_RWD:  -11.28 \tLEN:  2848 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  128 \tRWD:  3.0 \tM_RWD:  -11.05 \tLEN:  3392 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  129 \tRWD:  6.0 \tM_RWD:  -10.79 \tLEN:  2772 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  130 \tRWD:  8.0 \tM_RWD:  -10.5 \tLEN:  2721 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  131 \tRWD:  8.0 \tM_RWD:  -10.21 \tLEN:  2387 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  132 \tRWD:  13.0 \tM_RWD:  -9.88 \tLEN:  2483 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  133 \tRWD:  14.0 \tM_RWD:  -9.54 \tLEN:  2277 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  134 \tRWD:  12.0 \tM_RWD:  -9.22 \tLEN:  2418 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  135 \tRWD:  13.0 \tM_RWD:  -8.88 \tLEN:  2395 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  136 \tRWD:  15.0 \tM_RWD:  -8.52 \tLEN:  2066 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  137 \tRWD:  6.0 \tM_RWD:  -8.31 \tLEN:  2807 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  138 \tRWD:  9.0 \tM_RWD:  -8.02 \tLEN:  2698 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  139 \tRWD:  5.0 \tM_RWD:  -7.78 \tLEN:  2811 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  140 \tRWD:  12.0 \tM_RWD:  -7.47 \tLEN:  2394 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  141 \tRWD:  15.0 \tM_RWD:  -7.12 \tLEN:  2149 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  142 \tRWD:  12.0 \tM_RWD:  -6.79 \tLEN:  2460 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  143 \tRWD:  10.0 \tM_RWD:  -6.48 \tLEN:  2842 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  144 \tRWD:  15.0 \tM_RWD:  -6.13 \tLEN:  2188 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  145 \tRWD:  11.0 \tM_RWD:  -5.83 \tLEN:  2219 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  146 \tRWD:  15.0 \tM_RWD:  -5.5 \tLEN:  2125 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  147 \tRWD:  12.0 \tM_RWD:  -5.17 \tLEN:  2325 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  148 \tRWD:  15.0 \tM_RWD:  -4.84 \tLEN:  2331 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  149 \tRWD:  12.0 \tM_RWD:  -4.56 \tLEN:  2356 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  150 \tRWD:  11.0 \tM_RWD:  -4.26 \tLEN:  2228 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  151 \tRWD:  15.0 \tM_RWD:  -3.92 \tLEN:  2317 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  152 \tRWD:  6.0 \tM_RWD:  -3.65 \tLEN:  2620 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  153 \tRWD:  16.0 \tM_RWD:  -3.35 \tLEN:  2040 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  154 \tRWD:  7.0 \tM_RWD:  -3.1 \tLEN:  2651 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  155 \tRWD:  13.0 \tM_RWD:  -2.8 \tLEN:  2559 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  156 \tRWD:  16.0 \tM_RWD:  -2.45 \tLEN:  1941 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  157 \tRWD:  13.0 \tM_RWD:  -2.14 \tLEN:  2306 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  158 \tRWD:  11.0 \tM_RWD:  -1.85 \tLEN:  2467 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  159 \tRWD:  15.0 \tM_RWD:  -1.52 \tLEN:  2137 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  160 \tRWD:  14.0 \tM_RWD:  -1.19 \tLEN:  2333 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  161 \tRWD:  12.0 \tM_RWD:  -0.88 \tLEN:  2443 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  162 \tRWD:  15.0 \tM_RWD:  -0.55 \tLEN:  2316 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  163 \tRWD:  17.0 \tM_RWD:  -0.24 \tLEN:  2004 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  164 \tRWD:  8.0 \tM_RWD:  -0.02 \tLEN:  2525 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  165 \tRWD:  16.0 \tM_RWD:  0.3 \tLEN:  2031 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  166 \tRWD:  13.0 \tM_RWD:  0.59 \tLEN:  2088 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  167 \tRWD:  15.0 \tM_RWD:  0.89 \tLEN:  2146 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  168 \tRWD:  14.0 \tM_RWD:  1.23 \tLEN:  2365 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  169 \tRWD:  10.0 \tM_RWD:  1.48 \tLEN:  2505 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  170 \tRWD:  18.0 \tM_RWD:  1.85 \tLEN:  2125 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  171 \tRWD:  14.0 \tM_RWD:  2.13 \tLEN:  2022 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  172 \tRWD:  16.0 \tM_RWD:  2.47 \tLEN:  2117 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  173 \tRWD:  17.0 \tM_RWD:  2.78 \tLEN:  2008 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  174 \tRWD:  14.0 \tM_RWD:  3.11 \tLEN:  2072 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  175 \tRWD:  18.0 \tM_RWD:  3.45 \tLEN:  2204 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  176 \tRWD:  16.0 \tM_RWD:  3.72 \tLEN:  2308 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  177 \tRWD:  17.0 \tM_RWD:  4.02 \tLEN:  1992 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  178 \tRWD:  11.0 \tM_RWD:  4.31 \tLEN:  2523 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  179 \tRWD:  18.0 \tM_RWD:  4.63 \tLEN:  1868 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  180 \tRWD:  18.0 \tM_RWD:  4.93 \tLEN:  1973 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  181 \tRWD:  17.0 \tM_RWD:  5.23 \tLEN:  1943 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  182 \tRWD:  12.0 \tM_RWD:  5.41 \tLEN:  2491 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  183 \tRWD:  17.0 \tM_RWD:  5.65 \tLEN:  1873 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  184 \tRWD:  13.0 \tM_RWD:  5.83 \tLEN:  2405 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  185 \tRWD:  12.0 \tM_RWD:  6.02 \tLEN:  2349 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  186 \tRWD:  14.0 \tM_RWD:  6.26 \tLEN:  2360 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  187 \tRWD:  15.0 \tM_RWD:  6.51 \tLEN:  2197 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  188 \tRWD:  18.0 \tM_RWD:  6.76 \tLEN:  1865 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  189 \tRWD:  14.0 \tM_RWD:  6.94 \tLEN:  2480 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  190 \tRWD:  14.0 \tM_RWD:  7.14 \tLEN:  2409 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  191 \tRWD:  14.0 \tM_RWD:  7.35 \tLEN:  2238 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  192 \tRWD:  16.0 \tM_RWD:  7.56 \tLEN:  2043 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  193 \tRWD:  17.0 \tM_RWD:  7.76 \tLEN:  2138 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  194 \tRWD:  14.0 \tM_RWD:  7.92 \tLEN:  2224 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  195 \tRWD:  17.0 \tM_RWD:  8.19 \tLEN:  1931 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  196 \tRWD:  17.0 \tM_RWD:  8.41 \tLEN:  1862 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  197 \tRWD:  15.0 \tM_RWD:  8.57 \tLEN:  2045 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  198 \tRWD:  15.0 \tM_RWD:  8.81 \tLEN:  2075 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  199 \tRWD:  13.0 \tM_RWD:  8.96 \tLEN:  2252 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  200 \tRWD:  14.0 \tM_RWD:  9.15 \tLEN:  2068 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  201 \tRWD:  12.0 \tM_RWD:  9.33 \tLEN:  2102 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  202 \tRWD:  14.0 \tM_RWD:  9.51 \tLEN:  2135 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  203 \tRWD:  14.0 \tM_RWD:  9.67 \tLEN:  2056 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  204 \tRWD:  17.0 \tM_RWD:  9.8 \tLEN:  1882 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  205 \tRWD:  13.0 \tM_RWD:  9.94 \tLEN:  2463 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  206 \tRWD:  18.0 \tM_RWD:  10.21 \tLEN:  1929 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  207 \tRWD:  16.0 \tM_RWD:  10.46 \tLEN:  1975 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  208 \tRWD:  16.0 \tM_RWD:  10.71 \tLEN:  1976 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  209 \tRWD:  19.0 \tM_RWD:  10.94 \tLEN:  1861 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  210 \tRWD:  19.0 \tM_RWD:  11.18 \tLEN:  1848 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  211 \tRWD:  15.0 \tM_RWD:  11.37 \tLEN:  2058 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  212 \tRWD:  14.0 \tM_RWD:  11.54 \tLEN:  2285 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  213 \tRWD:  12.0 \tM_RWD:  11.69 \tLEN:  2273 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  214 \tRWD:  19.0 \tM_RWD:  11.82 \tLEN:  1830 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  215 \tRWD:  12.0 \tM_RWD:  11.88 \tLEN:  2415 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  216 \tRWD:  12.0 \tM_RWD:  11.98 \tLEN:  2578 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  217 \tRWD:  14.0 \tM_RWD:  12.1 \tLEN:  1975 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  218 \tRWD:  17.0 \tM_RWD:  12.36 \tLEN:  2039 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  219 \tRWD:  15.0 \tM_RWD:  12.52 \tLEN:  2053 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  220 \tRWD:  20.0 \tM_RWD:  12.74 \tLEN:  1708 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  221 \tRWD:  14.0 \tM_RWD:  12.91 \tLEN:  2098 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  222 \tRWD:  12.0 \tM_RWD:  13.07 \tLEN:  2312 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  223 \tRWD:  17.0 \tM_RWD:  13.25 \tLEN:  2059 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  224 \tRWD:  18.0 \tM_RWD:  13.51 \tLEN:  1915 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  225 \tRWD:  12.0 \tM_RWD:  13.6 \tLEN:  2246 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  226 \tRWD:  13.0 \tM_RWD:  13.71 \tLEN:  2198 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  227 \tRWD:  12.0 \tM_RWD:  13.79 \tLEN:  2288 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  228 \tRWD:  19.0 \tM_RWD:  13.95 \tLEN:  1874 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  229 \tRWD:  16.0 \tM_RWD:  14.05 \tLEN:  2088 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  230 \tRWD:  12.0 \tM_RWD:  14.09 \tLEN:  2257 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  231 \tRWD:  16.0 \tM_RWD:  14.17 \tLEN:  2062 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  232 \tRWD:  17.0 \tM_RWD:  14.21 \tLEN:  2068 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  233 \tRWD:  17.0 \tM_RWD:  14.24 \tLEN:  2054 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  234 \tRWD:  14.0 \tM_RWD:  14.26 \tLEN:  2492 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  235 \tRWD:  19.0 \tM_RWD:  14.32 \tLEN:  1896 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  236 \tRWD:  17.0 \tM_RWD:  14.34 \tLEN:  1885 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  237 \tRWD:  12.0 \tM_RWD:  14.4 \tLEN:  2469 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  238 \tRWD:  19.0 \tM_RWD:  14.5 \tLEN:  1838 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  239 \tRWD:  14.0 \tM_RWD:  14.59 \tLEN:  2260 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  240 \tRWD:  19.0 \tM_RWD:  14.66 \tLEN:  1904 \tEPS:  0.06\n","[INFO] Saving model\n","[INFO] Saving model\n","ITER:  241 \tRWD:  16.0 \tM_RWD:  14.67 \tLEN:  1967 \tEPS:  0.06\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{},"source":["# Testing"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["env_name = 'PongNoFrameskip-v4'\n","env = make_env(env_name)\n","\n","agent = DQNAgent(observation_shape=env.observation_space.shape,\n","                 n_actions=env.action_space.n,\n","                 lr=1e-4,\n","                 gamma=0.99,\n","                 epsilon=0.001,\n","                 epsilon_min=0.001,\n","                 epsilon_decay=1e-5,\n","                 mem_size=1,\n","                 batch_size=1,\n","                 Q_TARGET_replace_interval=1000,\n","                 algo_name='DQN',\n","                 env_name=env_name,\n","                 model_dir='./')"]},{"cell_type":"code","execution_count":10,"metadata":{"tags":[]},"outputs":[{"output_type":"stream","name":"stdout","text":"[INFO] Loading model\n[INFO] Loading model\n"}],"source":["agent.load_models(cpu=True)"]},{"cell_type":"code","execution_count":20,"metadata":{"tags":[]},"outputs":[{"output_type":"stream","name":"stdout","text":"RWD:  20.0 \tLEN:  1753\n"}],"source":["with T.no_grad():\n","    total_reward, total_moves = 0,0\n","    done = False\n","    observation = env.reset()\n","\n","    while not done:\n","        time.sleep(0.0001)\n","        env.render()\n","\n","        # e_GREEDY ACTION\n","        action = agent.get_action(observation, greedy=True)\n","        observation_, reward, done, _ = env.step(action)\n","\n","        total_reward += reward\n","        total_moves += 1\n","\n","        observation = observation_\n","    print(\"RWD: \",total_reward,\"\\tLEN: \",total_moves)\n","    env.close()"]}]}